{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd9d359c",
   "metadata": {},
   "source": [
    "## Preflight Check\n",
    "\n",
    "If this fails with 401, regenerate OpenRouter key and restart kernel.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16bc0d5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL WORKING\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "load_dotenv(dotenv_path=\".env\", override=False)\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    api_key=os.environ[\"OPENROUTER_API_KEY\"].strip(),\n",
    "    default_headers={\n",
    "        \"HTTP-Referer\": \"http://localhost:8888\",\n",
    "        \"X-Title\": \"Dallas Agent Workshop\",\n",
    "    },\n",
    ")\n",
    "\n",
    "resp = client.chat.completions.create(\n",
    "    model=os.getenv(\"OPENROUTER_MODEL\", \"arcee-ai/trinity-large-preview:free\"),\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Reply with exactly: MODEL WORKING\"}],\n",
    ")\n",
    "\n",
    "print(resp.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ef53b8",
   "metadata": {},
   "source": [
    "# Dallas AI ‚Äî Hands-on Agent Building (LangGraph + OpenRouter)\n",
    "\n",
    "This notebook is the main workshop surface:\n",
    "- You will run the agent locally.\n",
    "- The model is accessed via OpenRouter.\n",
    "- The agent can generate Python code and execute it using a controlled tool.\n",
    "\n",
    "**Goal:** experience a real *plan ‚Üí code ‚Üí execute ‚Üí fix* loop.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa22e19",
   "metadata": {},
   "source": [
    "## Agenda\n",
    "\n",
    "- 5:30 - Check-in, food, networking (30)\n",
    "- 6:00 - Why Agents? (Motivation & Framing) (5)\n",
    "- 6:05 - Core Concepts & Architectures (5)\n",
    "- 6:10 - Setup & Environment (30)\n",
    "- 6:40 - Live Code Walkthrough (20)\n",
    "- 7:00 - Hands-On Build Session (40)\n",
    "- 7:40 - Engineering Discipline for Agents (10)\n",
    "- 7:50 - Next: Virtual sessions, submitting PRs (10)\n",
    "- 8:00 - Curated Resources\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c529c9ef",
   "metadata": {},
   "source": [
    "## Why Agents? (Motivation & Framing)\n",
    "\n",
    "An agent is a loop that can **plan**, **use tools**, and **iterate** toward a goal. In this workshop, the agent can:\n",
    "- Write Python code\n",
    "- Execute it in a controlled way\n",
    "- Read the result (stdout/stderr) and try again\n",
    "\n",
    "Why this matters: lots of real work is not a single prompt. It needs multi-step problem solving, verification, and guardrails.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33508b85",
   "metadata": {},
   "source": [
    "## Core Concepts & Architectures\n",
    "\n",
    "We will use a simple LangGraph workflow that looks like:\n",
    "\n",
    "`plan -> exec -> (fix -> exec)* -> finish`\n",
    "\n",
    "Key ideas:\n",
    "- **State**: the data that flows between steps (task, generated code, last run result).\n",
    "- **Tools**: the controlled actions the agent can take (here: running Python; for research: web search).\n",
    "- **Guardrails**: constraints that keep the agent safe/reliable (timeouts, blocked imports, \"must print\" requirement).\n",
    "- **Evaluation mindset**: make the agent produce observable outputs so you can debug quickly (stdout, logs, reproducible steps).\n",
    "\n",
    "During the live walkthrough, we will inspect `agent_lib.py` and connect each node to what you see on screen.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8951d183",
   "metadata": {},
   "source": [
    "## 0) Setup\n",
    "\n",
    "1. Create a venv and install deps:\n",
    "```bash\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "2. Copy `.env.example` to `.env` and set `OPENROUTER_API_KEY`.\n",
    "3. Restart kernel after editing `.env`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3898aa44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "repr: 'e000c20e40'\n",
      "endswith newline? False\n",
      "has spaces? False\n",
      "len raw: 73 len strip: 73\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"OPENROUTER_MODEL\"] = \"arcee-ai/trinity-large-preview:free\"\n",
    "\n",
    "k = os.environ[\"OPENROUTER_API_KEY\"]\n",
    "print(\"repr:\", repr(k[-10:]))\n",
    "print(\"endswith newline?\", k.endswith(\"\\n\"))\n",
    "print(\"has spaces?\", (\" \" in k))\n",
    "print(\"len raw:\", len(k), \"len strip:\", len(k.strip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0a3afab-4035-4279-871a-37ef4a0c687b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "{\"data\":[{\"id\":\"google/gemini-3.1-pro-preview\",\"canonical_slug\":\"google/gemini-3.1-pro-preview-20260219\",\"hugging_face_id\":\"\",\"name\":\"Google: Gemini 3.1 Pro Preview\",\"created\":1771509627,\"description\":\"Gemini 3.1 Pro Preview is Google‚Äôs frontier reasoning model, delivering enhanced software engineer\n"
     ]
    }
   ],
   "source": [
    "import os, requests\n",
    "headers = {\"Authorization\": f\"Bearer {os.environ['OPENROUTER_API_KEY'].strip()}\"}\n",
    "r = requests.get(\"https://openrouter.ai/api/v1/models\", headers=headers, timeout=20)\n",
    "print(r.status_code)\n",
    "print(r.text[:300])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ac4256",
   "metadata": {},
   "source": [
    "## 1) Sanity check: run the Python execution tool\n",
    "\n",
    "This runs locally with timeouts and basic restrictions. It is **not** a hardened sandbox.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6994df79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ok': True,\n",
       " 'stdout': 'hello from tool\\n6\\n',\n",
       " 'stderr': '',\n",
       " 'exit_code': 0,\n",
       " 'note': 'Execution policy: temporary working directory, time-limited, and blocks some risky imports/calls. This is NOT a hardened sandbox.'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tools import run_python\n",
    "\n",
    "code = \"\"\"\n",
    "print('hello from tool')\n",
    "print(sum([1,2,3]))\n",
    "\"\"\"\n",
    "\n",
    "run_python(code)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6314648a",
   "metadata": {},
   "source": [
    "## 2) Run a single agent task\n",
    "\n",
    "We will run one end-to-end task:\n",
    "- Planner proposes solution + code\n",
    "- Executor runs code\n",
    "- If fails, Fixer patches and retries (up to 3 attempts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e549b8a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== GENERATED CODE ===\n",
      "# iterative approach to compute Fibonacci(35)\n",
      "a, b = 0, 1\n",
      "for _ in range(35):\n",
      "    a, b = b, a + b\n",
      "print(a)\n",
      "======================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ok': True,\n",
       " 'stdout': '9227465\\n',\n",
       " 'stderr': '',\n",
       " 'exit_code': 0,\n",
       " 'note': 'Execution policy: temporary working directory, time-limited, and blocks some risky imports/calls. This is NOT a hardened sandbox.'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from agent_lib import run_task\n",
    "\n",
    "task = \"Write a Python function to compute Fibonacci(n) efficiently and print Fibonacci(35).\"\n",
    "result = run_task(task)\n",
    "\n",
    "result['last_run']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a672d9",
   "metadata": {},
   "source": [
    "## 3) Workshop exercises\n",
    "\n",
    "Try the tasks below. You can also author your own.\n",
    "Tip: keep tasks self-contained and offline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e25ceab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TASK: Parse this CSV string and compute the average of the 'latency_ms' column:\n",
      "\n",
      "ts,latency_ms\n",
      "1,120\n",
      "2,110\n",
      "3,130\n",
      "4,90\n",
      "\n",
      "=== GENERATED CODE ===\n",
      "import csv\n",
      "from io import StringIO\n",
      "\n",
      "csv_string = \"\"\"ts,latency_ms\n",
      "1,120\n",
      "2,110\n",
      "3,130\n",
      "4,90\"\"\"\n",
      "\n",
      "f = StringIO(csv_string)\n",
      "reader = csv.DictReader(f)\n",
      "latencies = [int(row['latency_ms']) for row in reader]\n",
      "average = sum(latencies) / len(latencies)\n",
      "print(average)\n",
      "======================\n",
      "OK: True\n",
      "STDOUT:\n",
      " 112.5\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TASK: Implement rolling z-score anomaly score for this list and print the top 3 most anomalous points: [10,11,9,10,10,200,11,10,9,10]\n",
      "=== GENERATED CODE ===\n",
      "import numpy as np\n",
      "\n",
      "data = [10, 11, 9, 10, 10, 200, 11, 10, 9, 10]\n",
      "window_size = 3\n",
      "\n",
      "z_scores = []\n",
      "for i in range(window_size - 1, len(data)):\n",
      "    window = data[i - window_size + 1:i + 1]\n",
      "    mean = np.mean(window)\n",
      "    std = np.std(window, ddof=1)  # Use sample std (ddof=1)\n",
      "    if std == 0:\n",
      "        z = 0\n",
      "    else:\n",
      "        z = (data[i] - mean) / std\n",
      "    z_scores.append((i, data[i], z))\n",
      "\n",
      "# Sort by absolute z-score in descending order\n",
      "z_scores_sorted = sorted(z_scores, key=lambda x: abs(x[2]), reverse=True)\n",
      "\n",
      "print(\"Top 3 most anomalous points:\")\n",
      "for i in range(min(3, len(z_scores_sorted))):\n",
      "    idx, value, z = z_scores_sorted[i]\n",
      "    print(f\"Index {idx}: value={value}, z-score={z:.2f}\")\n",
      "======================\n",
      "=== GENERATED CODE ===\n",
      "data = [10, 11, 9, 10, 10, 200, 11, 10, 9, 10]\n",
      "window_size = 3\n",
      "\n",
      "z_scores = []\n",
      "for i in range(window_size - 1, len(data)):\n",
      "    window = data[i - window_size + 1:i + 1]\n",
      "    mean = sum(window) / len(window)\n",
      "    variance = sum((x - mean) ** 2 for x in window) / (len(window) - 1)  # sample variance\n",
      "    std = variance ** 0.5\n",
      "    if std == 0:\n",
      "        z = 0\n",
      "    else:\n",
      "        z = (data[i] - mean) / std\n",
      "    z_scores.append((i, data[i], z))\n",
      "\n",
      "# Sort by absolute z-score in descending order\n",
      "z_scores_sorted = sorted(z_scores, key=lambda x: abs(x[2]), reverse=True)\n",
      "\n",
      "print(\"Top 3 most anomalous points:\")\n",
      "for i in range(min(3, len(z_scores_sorted))):\n",
      "    idx, value, z = z_scores_sorted[i]\n",
      "    print(f\"Index {idx}: value={value}, z-score={z:.2f}\")\n",
      "======================\n",
      "OK: True\n",
      "STDOUT:\n",
      " Top 3 most anomalous points:\n",
      "Index 5: value=200, z-score=1.15\n",
      "Index 2: value=9, z-score=-1.00\n",
      "Index 8: value=9, z-score=-1.00\n",
      "\n",
      "\n",
      "================================================================================\n",
      "TASK: Given a list of (user_id, event_time, event_type), compute per-user session counts (30-min gap) and print a dict.\n",
      "=== GENERATED CODE ===\n",
      "# executable Python code\n",
      "# must include print(...)\n",
      "\n",
      "from datetime import datetime, timedelta\n",
      "\n",
      "# Sample input data\n",
      "events = [\n",
      "    (1, '2023-10-01 10:00:00', 'click'),\n",
      "    (1, '2023-10-01 10:15:00', 'view'),\n",
      "    (1, '2023-10-01 10:45:00', 'click'),\n",
      "    (2, '2023-10-01 11:00:00', 'click'),\n",
      "    (2, '2023-10-01 11:20:00', 'view'),\n",
      "    (2, '2023-10-01 11:50:00', 'click'),\n",
      "    (1, '2023-10-01 12:00:00', 'view')\n",
      "]\n",
      "\n",
      "# Parse and sort events by user_id and event_time\n",
      "events.sort(key=lambda x: (x[0], datetime.strptime(x[1], '%Y-%m-%d %H:%M:%S')))\n",
      "\n",
      "# Dictionary to store session counts per user\n",
      "session_counts = {}\n",
      "\n",
      "# Process events\n",
      "current_user = None\n",
      "session_start = None\n",
      "session_count = 0\n",
      "\n",
      "for user_id, event_time_str, event_type in events:\n",
      "    event_time = datetime.strptime(event_time_str, '%Y-%m-%d %H:%M:%S')\n",
      "\n",
      "    if user_id != current_user:\n",
      "        # New user, finalize previous user's session count\n",
      "        if current_user is not None:\n",
      "            session_counts[current_user] = session_count\n",
      "        # Reset for new user\n",
      "        current_user = user_id\n",
      "        session_start = event_time\n",
      "        session_count = 1\n",
      "    else:\n",
      "        # Same user, check if within 30 minutes of session start\n",
      "        if event_time - session_start > timedelta(minutes=30):\n",
      "            session_count += 1\n",
      "            session_start = event_time\n",
      "        # else: still in the same session, no change\n",
      "\n",
      "# Finalize the last user\n",
      "if current_user is not None:\n",
      "    session_counts[current_user] = session_count\n",
      "\n",
      "print(session_counts)\n",
      "======================\n",
      "OK: True\n",
      "STDOUT:\n",
      " {1: 3, 2: 2}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tasks = [\n",
    "    \"Parse this CSV string and compute the average of the 'latency_ms' column:\\n\\nts,latency_ms\\n1,120\\n2,110\\n3,130\\n4,90\\n\",\n",
    "    \"Implement rolling z-score anomaly score for this list and print the top 3 most anomalous points: [10,11,9,10,10,200,11,10,9,10]\",\n",
    "    \"Given a list of (user_id, event_time, event_type), compute per-user session counts (30-min gap) and print a dict.\"\n",
    "]\n",
    "\n",
    "for t in tasks:\n",
    "    print('\\n' + '='*80)\n",
    "    print('TASK:', t)\n",
    "    out = run_task(t)\n",
    "    print('OK:', out['last_run']['ok'])\n",
    "    print('STDOUT:\\n', out['last_run']['stdout'])\n",
    "    if not out['last_run']['ok']:\n",
    "        print('STDERR:\\n', out['last_run']['stderr'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1d53e9",
   "metadata": {},
   "source": [
    "## 3a) Advanced: tighten/loosen execution policy\n",
    "\n",
    "In `tools.py`, you can change:\n",
    "- timeout\n",
    "- banned patterns\n",
    "\n",
    "For meetup safety, keep it restrictive.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "research_agent_intro",
   "metadata": {},
   "source": [
    "## 4) Applied Exercise: Research Agent\n",
    "\n",
    "Unlike the code-execution agent, this agent:\n",
    "- Plans multi-step searches\n",
    "- Gathers information from the web via Tavily\n",
    "- Synthesizes findings into a structured report\n",
    "\n",
    "**Use case:** competitive intelligence, market research, due diligence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "research_setup",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESEARCH QUESTION:\n",
      "What are the top 3 AI chip companies in 2024 and what's their competitive advantage?\n",
      "\n",
      "\n",
      "============================================================\n",
      "PLANNED QUERIES:\n",
      "  1. top AI chip companies 2024 competitive advantage\n",
      "  2. leading AI chip manufacturers 2024 market position\n",
      "  3. AI chip industry leaders 2024 technology comparison\n",
      "============================================================\n",
      "\n",
      "üîç Searching: top AI chip companies 2024 competitive advantage\n",
      "   ‚Üí Found 3 sources\n",
      "üîç Searching: leading AI chip manufacturers 2024 market position\n",
      "   ‚Üí Found 3 sources\n",
      "üîç Searching: AI chip industry leaders 2024 technology comparison\n",
      "   ‚Üí Found 3 sources\n",
      "\n",
      "‚úì Collected 9 total sources\n",
      "\n",
      "\n",
      "============================================================\n",
      "FINAL REPORT:\n",
      "============================================================\n",
      "**Executive Summary**\n",
      "NVIDIA, AMD, and Google (Alphabet) are the top three AI chip companies in 2024, each leveraging distinct competitive advantages. NVIDIA dominates with over 70% of AI semiconductor sales, AMD offers cost-effective solutions, and Google excels in custom AI chip development for its ecosystem.\n",
      "\n",
      "**Key Findings**\n",
      "- NVIDIA leads the AI chip market with over 70% of AI semiconductor sales, benefiting from years of innovation and technology leadership [1][5].\n",
      "- AMD positions itself as a cost-effective and high-performance alternative, with products like the Instinct MI300X accelerator featuring 192GB of HBM3 memory [4][9].\n",
      "- Google (Alphabet) is a major player, producing its own AI chips and competing with traditional chip makers in innovation and technology [1][4].\n",
      "- Traditional chip makers like NVIDIA, AMD, AVGO, and INTC are expected to have an edge over data center/search companies in innovation and technology due to their extensive experience [1][5].\n",
      "- The AI chip market is driven by extensive R&D spending and investment, with companies focusing on improving chip architecture and software optimization [2][6].\n",
      "\n",
      "**Conclusion**\n",
      "NVIDIA, AMD, and Google are the top AI chip companies in 2024, each with unique strengths: NVIDIA's market dominance, AMD's cost-effectiveness, and Google's custom chip development. The market remains highly competitive, with traditional chip makers maintaining an edge in innovation.\n"
     ]
    }
   ],
   "source": [
    "from research_agent import run_research\n",
    "\n",
    "question = \"What are the top 3 AI chip companies in 2024 and what's their competitive advantage?\"\n",
    "\n",
    "print(f\"RESEARCH QUESTION:\\n{question}\\n\")\n",
    "\n",
    "result = run_research(question)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FINAL REPORT:\")\n",
    "print(\"=\"*60)\n",
    "print(result[\"report\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5433071e",
   "metadata": {},
   "source": [
    "## 5) Engineering Discipline for Agents\n",
    "\n",
    "Agents feel \"magical\" until they fail. The fastest way to make them reliable is good engineering hygiene:\n",
    "\n",
    "- **State management**: write down what the agent knows (inputs/outputs) and pass it explicitly.\n",
    "- **Context management**: keep prompts short and structured; include only what is necessary; summarize when needed.\n",
    "- **Memory (optional)**: decide what should persist across runs (none vs. per-session vs. long-term).\n",
    "- **Token budgeting**: constrain output formats; avoid dumping large logs or huge documents into the model.\n",
    "- **Governance & safety**: limit tools and permissions; log tool calls; treat credentials carefully; assume untrusted outputs.\n",
    "\n",
    "In this repo, we keep things workshop-safe by forcing observable stdout, logging generated code, adding timeouts, and blocking risky Python calls.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54471519",
   "metadata": {},
   "source": [
    "## 7) Next: Virtual sessions + Submitting PRs\n",
    "\n",
    "Stretch goals (great for follow-up sessions):\n",
    "- Add more tools (file I/O, data APIs) with careful safety boundaries\n",
    "- Turn the workflow into multiple collaborating agents (planner + specialists)\n",
    "- Add lightweight evaluations (golden tests, regression prompts, success criteria)\n",
    "\n",
    "If you improve the workshop materials, please open a PR against this repo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42001676",
   "metadata": {},
   "source": [
    "## 8) Curated Resources\n",
    "\n",
    "- Prompting best practices (Claude): https://platform.claude.com/docs/en/build-with-claude/prompt-engineering/claude-prompting-best-practices\n",
    "- LangGraph docs: https://langchain-ai.github.io/langgraph/\n",
    "- OpenRouter docs: https://openrouter.ai/docs\n",
    "\n",
    "Tip: when learning, keep a small set of repeatable test prompts (like `2+2`, Fibonacci, CSV parse) to validate changes quickly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21269bc7",
   "metadata": {},
   "source": [
    "## 6) Optional: make it multi-agent\n",
    "\n",
    "You can extend `agent_lib.py` into multiple agents:\n",
    "- planner\n",
    "- coder\n",
    "- executor\n",
    "- verifier\n",
    "\n",
    "LangGraph makes these edges explicit.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148e2e7a-cb87-4ccf-9f22-5c8e7380ad84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
